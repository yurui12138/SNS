# SNSæ–¹æ³•å®ç°æ”¹è¿›å»ºè®®

**æ—¥æœŸ**: 2025-12-15  
**é¡¹ç›®**: SNS (Self-Nonself) for Automatic Survey Generation

---

## æ‰§è¡Œæ‘˜è¦

æœ¬æ–‡æ¡£åŸºäºå¯¹SNSæ–¹æ³•è¯´æ˜æ–‡æ¡£ä¸å½“å‰ä»£ç å®ç°çš„è¯¦ç»†å¯¹æ¯”åˆ†æ,æå‡ºé’ˆå¯¹æ€§çš„æ”¹è¿›å»ºè®®ã€‚**å½“å‰å®ç°å®Œæ•´åº¦ä¸º80%**,å­˜åœ¨4ä¸ªCriticalçº§åˆ«çš„ç¼ºå¤±åŠŸèƒ½,ä½†æ¶æ„ä¼˜ç§€ä¸”å…³é”®åŸºç¡€è®¾æ–½(Embeddings, NLI)å·²å®ç°,é¢„è®¡**5-7ä¸ªå·¥ä½œæ—¥å¯è¡¥é½æ‰€æœ‰Critical issues**ã€‚

### å…³é”®å‘ç°

âœ… **ä¼˜åŠ¿**:
- æ•°æ®ç»“æ„ä½“ç³»å®Œæ•´ (100%å¯¹é½æ–¹æ³•è¯´æ˜)
- Pipelineæ¶æ„æ¸…æ™° (Phase 1-4æµç¨‹å®Œæ•´)
- å…³é”®åŸºç¡€è®¾æ–½å·²å®ç° (embeddings.py, nli.pyå­˜åœ¨ä¸”å®Œæ•´)
- è®¾è®¡å†³ç­–æ­£ç¡® (Reconstruct-then-select, Writing Modeç­‰)

âš ï¸ **éœ€è¦æ”¹è¿›**:
- Phase 2æœªä½¿ç”¨çœŸå®Embeddingså’ŒNLI (ä½¿ç”¨placeholder)
- è¡¥è§†è§’ç­–ç•¥æœªå®ç° (åªæœ‰warning)
- SPLIT_NODEå’ŒRENAME_NODEæœªå®ç° (åªæœ‰TODO)
- Taxonomy_v2æœªåº”ç”¨Evolution (è¾“å‡ºçš„æ˜¯åŸå§‹ç‰ˆæœ¬)

---

## æ”¹è¿›ä¼˜å…ˆçº§

### ğŸ”´ Priority 1 (Critical - Week 1)

#### 1.1 é›†æˆçœŸå®Embeddingså’ŒNLIåˆ°Phase 2

**å½“å‰é—®é¢˜**:
- `phase2_stress_test.py` ä½¿ç”¨keyword overlapè®¡ç®—ç›¸ä¼¼åº¦
- `FitTester._calculate_conflict()` ä½¿ç”¨ç®€å•keywordåŒ¹é…

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# åœ¨ EmbeddingBasedRetriever.__init__()
from ..embeddings import create_embedding_model
self.embedder = create_embedding_model(model_type="specter2", device="cpu")

# åœ¨ FitTester.__init__()
from ..nli import create_nli_model
self.nli_model = create_nli_model(model_type="deberta", device="cpu")
```

**é¢„æœŸæ•ˆæœ**:
- Coverageåˆ†æ•°å‡†ç¡®åº¦æå‡ (åŸºäºSPECTER2)
- Conflictåˆ†æ•°å‡†ç¡®åº¦æå‡ (åŸºäºDeBERTa-MNLI)
- FITåˆ¤å®šå‡†ç¡®ç‡æå‡

**å·¥ä½œé‡**: 4-6å°æ—¶

---

#### 1.2 å®ç°è¡¥è§†è§’ç­–ç•¥

**å½“å‰é—®é¢˜**:
- `_check_baseline_quality()` åªwarning,ä¸è¡¥æ•‘
- å½“ç»¼è¿°è´¨é‡ä¸è¶³æ—¶ç³»ç»Ÿæ— æ³•æ¢å¤

**æ”¹è¿›æ–¹æ¡ˆ**:
åˆ›å»º `knowledge/sns/modules/compensatory_view.py`:
```python
class CompensatoryViewInducer:
    def should_induce(self, baseline) -> bool:
        # æ£€æŸ¥unique facets < 2 æˆ– dominant > 60%
    
    def induce_view(self, baseline, papers, topic) -> TaxonomyView:
        # 1. å¯¹è®ºæ–‡HDBSCANèšç±»
        # 2. LLMç”Ÿæˆç°‡æ ‡ç­¾
        # 3. æ„å»ºflat tree (root + leaves)
        # 4. é€‰æ‹©unique facet
        # 5. åˆ›å»ºTaxonomyView with weight=0.5
```

**é›†æˆåˆ°Phase1Pipeline**:
```python
def run(self, topic):
    # ... ç°æœ‰ä»£ç  ...
    
    # æ–°å¢: è¡¥è§†è§’æ£€æŸ¥ä¸è§¦å‘
    if self.compensatory_inducer.should_induce(baseline):
        compensatory_view = self.compensatory_inducer.induce_view(
            baseline, self.cached_papers, topic
        )
        if compensatory_view:
            baseline.views.append(compensatory_view)
            baseline.__post_init__()  # é‡æ–°å½’ä¸€åŒ–æƒé‡
```

**é¢„æœŸæ•ˆæœ**:
- Baselineå§‹ç»ˆæ»¡è¶³è´¨é‡æ ‡å‡†
- ç³»ç»Ÿé²æ£’æ€§æå‡

**å·¥ä½œé‡**: 1-2å¤©

---

### ğŸŸ¡ Priority 2 (High - Week 2-3)

#### 2.1 å®ç°SPLIT_NODEæ“ä½œ

**å½“å‰é—®é¢˜**:
- åªæœ‰ADD_NODE,æ— æ³•å¤„ç†overcrowdedèŠ‚ç‚¹

**æ”¹è¿›æ–¹æ¡ˆ**:
åœ¨ `phase3_evolution.py` æ·»åŠ :
```python
def _propose_split_node(self, cluster, view, fit_vectors) -> Optional[SplitNodeOperation]:
    # 1. è¯†åˆ«overcrowdedå¶èŠ‚ç‚¹ (è®ºæ–‡æ•° > 15)
    # 2. å¯¹èŠ‚ç‚¹å†…è®ºæ–‡sub-clustering
    # 3. LLMç”Ÿæˆå­èŠ‚ç‚¹å®šä¹‰
    # 4. è®¡ç®—fit_gain
    # 5. è¿”å›SplitNodeOperation (cost=2.0)
```

**é¢„æœŸæ•ˆæœ**:
- å¯ä»¥å¤„ç†"èŠ‚ç‚¹è¿‡åº¦æ‹¥æŒ¤"åœºæ™¯
- Evolutionå»ºè®®æ›´å…¨é¢

**å·¥ä½œé‡**: 1å¤©

---

#### 2.2 å®ç°RENAME_NODEæ“ä½œ

**å½“å‰é—®é¢˜**:
- æ— æ³•å¤„ç†è¯­ä¹‰æ¼‚ç§»èŠ‚ç‚¹

**æ”¹è¿›æ–¹æ¡ˆ**:
åœ¨ `phase3_evolution.py` æ·»åŠ :
```python
def _propose_rename_node(self, cluster, view, fit_vectors) -> Optional[RenameNodeOperation]:
    # 1. è¯†åˆ«FORCE_FITç‡é«˜çš„å¶èŠ‚ç‚¹ (drift > 30%)
    # 2. åˆ†ælost_noveltyæå–æ–°ä¸»é¢˜
    # 3. LLMç”Ÿæˆæ–°åç§°å’Œå®šä¹‰
    # 4. è®¡ç®—fit_gain
    # 5. è¿”å›RenameNodeOperation (cost=0.5)
```

**é¢„æœŸæ•ˆæœ**:
- å¯ä»¥å¤„ç†"èŠ‚ç‚¹è¯­ä¹‰æ¼‚ç§»"åœºæ™¯
- Evolutionå»ºè®®å®Œæ•´

**å·¥ä½œé‡**: 1å¤©

---

#### 2.3 åº”ç”¨Evolutionåˆ°Taxonomyç”Ÿæˆv2

**å½“å‰é—®é¢˜**:
- `guidance_pack.json`è¾“å‡ºçš„taxonomyæ˜¯åŸå§‹ç‰ˆæœ¬
- ä¸‹æ¸¸ç³»ç»Ÿçœ‹ä¸åˆ°ç»“æ„æ›´æ–°

**æ”¹è¿›æ–¹æ¡ˆ**:
åˆ›å»º `knowledge/sns/modules/taxonomy_evolution_applier.py`:
```python
def apply_evolution_to_taxonomy(view, operations) -> TaxonomyView:
    view_v2 = copy.deepcopy(view)
    
    for op in operations:
        if isinstance(op, AddNodeOperation):
            # æ·»åŠ æ–°èŠ‚ç‚¹åˆ°tree
            new_node = TaxonomyTreeNode(...)
            view_v2.tree.add_node(new_node)
            view_v2.node_definitions[new_path] = NodeDefinition(...)
        
        elif isinstance(op, SplitNodeOperation):
            # å°†å¶èŠ‚ç‚¹å˜ä¸ºå†…éƒ¨èŠ‚ç‚¹,æ·»åŠ å­èŠ‚ç‚¹
        
        elif isinstance(op, RenameNodeOperation):
            # æ›´æ–°èŠ‚ç‚¹åç§°å’Œå®šä¹‰
    
    return view_v2
```

**é›†æˆåˆ°Phase4**:
```python
# åœ¨axis selectionä¹‹å‰åº”ç”¨evolution
baseline_v2 = apply_evolutions_to_all_views(baseline, evolution_proposal)
main_axis, mode = select_main_axis_with_mode(scores, baseline_v2)
```

**é¢„æœŸæ•ˆæœ**:
- ä¸‹æ¸¸ç³»ç»Ÿçœ‹åˆ°æ¼”åŒ–åçš„taxonomy
- è¾“å‡ºå®Œæ•´æ€§æå‡

**å·¥ä½œé‡**: 1-2å¤©

---

### ğŸŸ¢ Priority 3 (Medium - Week 4)

#### 3.1 å¢å¼ºMust-answer Questions

**å½“å‰é—®é¢˜**:
- é—®é¢˜è¿‡äºé€šç”¨ ("What are the key approaches?")

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
def _generate_must_answer_questions_enhanced(...):
    questions = []
    
    # 1. åŸºç¡€ç»“æ„é—®é¢˜
    questions.append(f"What are the main dimensions in {main_axis.facet_label}?")
    
    # 2. æ¯ä¸ªevolution operationä¸€ä¸ªé—®é¢˜
    for op in evolution_proposal.operations:
        if isinstance(op, AddNodeOperation):
            questions.append(
                f"Why was '{op.new_node.name}' added? "
                f"What papers don't fit existing structure?"
            )
    
    # 3. æ¯ä¸ªSTRONG_SHIFT clusterä¸€ä¸ªé—®é¢˜
    for cluster in clusters:
        if cluster.cluster_type == ClusterType.STRONG_SHIFT:
            questions.append(
                f"How do cluster {cluster.cluster_id}'s {len(cluster.papers)} papers "
                f"challenge existing {view.facet_label} organization?"
            )
    
    # 4. æ—§ç»“æ„ä¸è¶³è¯æ®é—®é¢˜ (å…³é”®!)
    questions.append(
        "What evidence shows existing taxonomies are insufficient? "
        "Cite specific FORCE_FIT or UNFITTABLE cases."
    )
    
    return questions
```

**é¢„æœŸæ•ˆæœ**:
- é—®é¢˜æ›´å…·é’ˆå¯¹æ€§
- å¼•å¯¼ä¸‹æ¸¸ç³»ç»Ÿå›ç­”å…³é”®æ¼”åŒ–é—®é¢˜

**å·¥ä½œé‡**: 4å°æ—¶

---

#### 3.2 æå‡Evidence Cardsè´¨é‡

**å½“å‰é—®é¢˜**:
- Evidence cardsåªåŒ…å«abstractå‰200å­—

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
def _create_subsection(...):
    # ... ç°æœ‰ä»£ç  ...
    
    # æ–°å¢: ä»fit_reportsæå–ç²¾ç¡®evidence
    evidence_cards = []
    for paper in relevant_papers[:5]:
        fv = next((f for f in fit_vectors if f.paper_id == paper.url), None)
        if fv:
            report = next((r for r in fv.fit_reports if r.view_id == main_axis.view_id), None)
            if report and report.lost_novelty:
                # ä½¿ç”¨lost_noveltyä½œä¸ºevidence
                for ln in report.lost_novelty[:2]:
                    evidence_cards.append(EvidenceCard(
                        paper_id=paper.url,
                        title=paper.title,
                        claim=ln.bullet,
                        quote=ln.evidence[0].quote if ln.evidence else "",
                        page=ln.evidence[0].page if ln.evidence else 0
                    ))
    
    # Fallback to abstract if no fit_reports
    if not evidence_cards:
        # ç°æœ‰é€»è¾‘
```

**é¢„æœŸæ•ˆæœ**:
- Evidence cardsåŒ…å«ç²¾ç¡®çš„novelty quotes
- å¯è¿½æº¯æ€§å¢å¼º

**å·¥ä½œé‡**: 2å°æ—¶

---

## å®æ–½è·¯çº¿å›¾

### Week 1: æ ¸å¿ƒåŠŸèƒ½è¡¥é½

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | è´Ÿè´£ |
|-----|--------|--------|------|
| 1.1 é›†æˆEmbeddings+NLI | ğŸ”´ Critical | 4-6h | Dev Team |
| 1.2 å®ç°è¡¥è§†è§’ç­–ç•¥ | ğŸ”´ Critical | 1-2d | Dev Team |
| æµ‹è¯• | ğŸ”´ Critical | 4h | QA Team |

**é‡Œç¨‹ç¢‘**: Phase 2å‡†ç¡®æ€§æå‡,baselineè´¨é‡ä¿è¯

---

### Week 2: Evolutionå®Œæ•´åŒ–

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | è´Ÿè´£ |
|-----|--------|--------|------|
| 2.1 å®ç°SPLIT_NODE | ğŸŸ¡ High | 1d | Dev Team |
| 2.2 å®ç°RENAME_NODE | ğŸŸ¡ High | 1d | Dev Team |
| 2.3 åº”ç”¨Evolutionåˆ°Taxonomy | ğŸ”´ Critical | 1-2d | Dev Team |
| æµ‹è¯• | ğŸŸ¡ High | 4h | QA Team |

**é‡Œç¨‹ç¢‘**: Evolution proposalå®Œæ•´,è¾“å‡ºåŒ…å«v2 taxonomy

---

### Week 3: è´¨é‡æå‡

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | è´Ÿè´£ |
|-----|--------|--------|------|
| 3.1 å¢å¼ºMust-answer Questions | ğŸŸ¢ Medium | 4h | Dev Team |
| 3.2 æå‡Evidence Cards | ğŸŸ¢ Medium | 2h | Dev Team |
| æ–‡æ¡£æ›´æ–° | ğŸŸ¢ Medium | 4h | Dev Team |
| ç«¯åˆ°ç«¯æµ‹è¯• | ğŸŸ¡ High | 1d | QA Team |

**é‡Œç¨‹ç¢‘**: è¾“å‡ºè´¨é‡è¾¾åˆ°ç”Ÿäº§æ ‡å‡†

---

### Week 4: ä¼˜åŒ–ä¸éƒ¨ç½²

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | è´Ÿè´£ |
|-----|--------|--------|------|
| æ€§èƒ½ä¼˜åŒ– (ç¼“å­˜, batch) | ğŸŸ¢ Medium | 1d | Dev Team |
| å‚æ•°è°ƒä¼˜ | ğŸŸ¢ Medium | 1d | Dev Team |
| Betaéƒ¨ç½² | ğŸŸ¡ High | 0.5d | DevOps |
| ç”¨æˆ·åé¦ˆæ”¶é›† | ğŸŸ¡ High | - | PM |

**é‡Œç¨‹ç¢‘**: ç³»ç»Ÿready for production

---

## æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•

```python
# Test 1: Embedding integration
def test_embedding_retriever():
    retriever = EmbeddingBasedRetriever("specter2")
    sim = retriever._compute_similarity("deep learning", "neural networks")
    assert 0 <= sim <= 1
    assert sim > 0.5  # åº”è¯¥ç›¸ä¼¼

# Test 2: NLI integration
def test_nli_conflict():
    tester = FitTester(retriever, nli_model)
    claims = PaperClaims(...)  # supervised learning paper
    node_def = NodeDefinition(  # unsupervised node
        exclusion_criteria=["supervised learning methods"]
    )
    conflict = tester._calculate_conflict(claims, node_def)
    assert conflict > 0.5  # åº”è¯¥æœ‰å†²çª

# Test 3: Compensatory view
def test_compensatory_inducer():
    inducer = CompensatoryViewInducer(embedder, lm)
    baseline = MultiViewBaseline(...)  # åªæœ‰1ä¸ªfacet
    assert inducer.should_induce(baseline) == True
    
    view = inducer.induce_view(baseline, papers, topic)
    assert view is not None
    assert view.facet_label != baseline.views[0].facet_label

# Test 4: Evolution applier
def test_evolution_applier():
    view = TaxonomyView(...)
    operations = [AddNodeOperation(...)]
    
    view_v2 = apply_evolution_to_taxonomy(view, operations)
    
    # éªŒè¯æ–°èŠ‚ç‚¹å­˜åœ¨
    assert "new_node_path" in view_v2.tree.nodes
    assert "new_node_path" in view_v2.node_definitions
```

### é›†æˆæµ‹è¯•

```python
# Test E2E: Complete pipeline
def test_sns_pipeline_e2e():
    runner = SNSRunner(args, lm_configs, rm)
    
    results = runner.run(
        do_phase1=True,
        do_phase2=True,
        do_phase3=True,
        do_phase4=True
    )
    
    # éªŒè¯è¾“å‡ºå®Œæ•´æ€§
    assert results.multiview_baseline is not None
    assert len(results.fit_vectors) > 0
    assert results.evolution_proposal is not None
    assert results.delta_aware_guidance is not None
    
    # éªŒè¯guidance_pack.json
    guidance_pack_path = os.path.join(args.output_dir, "guidance_pack.json")
    assert os.path.exists(guidance_pack_path)
    
    with open(guidance_pack_path) as f:
        pack = json.load(f)
        assert "writing_mode" in pack
        assert "taxonomy" in pack
        assert "outline" in pack
        assert "evolution_summary" in pack
    
    # éªŒè¯taxonomyåŒ…å«evolution
    if results.evolution_proposal.operations:
        # åº”è¯¥æœ‰æ–°å¢çš„èŠ‚ç‚¹
        main_axis = results.delta_aware_guidance.main_axis
        for op in results.evolution_proposal.operations:
            if isinstance(op, AddNodeOperation):
                assert any(op.new_node.name in node.name 
                          for node in main_axis.tree.nodes.values())
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. Embeddingç¼“å­˜

```python
class CachedEmbedder:
    def __init__(self, embedder):
        self.embedder = embedder
        self.cache = {}  # text -> embedding
    
    def encode(self, texts):
        to_encode = []
        cached_embeddings = []
        
        for text in texts:
            if text in self.cache:
                cached_embeddings.append(self.cache[text])
            else:
                to_encode.append(text)
        
        if to_encode:
            new_embeddings = self.embedder.encode(to_encode)
            for text, emb in zip(to_encode, new_embeddings):
                self.cache[text] = emb
        
        # åˆå¹¶ç¼“å­˜å’Œæ–°è®¡ç®—çš„
        # ...
```

### 2. NLIæ‰¹å¤„ç†

```python
# æ”¶é›†æ‰€æœ‰éœ€è¦æ£€æµ‹çš„(claim, exclusion)å¯¹
all_pairs = []
for claim in claims:
    for exclusion in node_def.exclusion_criteria:
        all_pairs.append((claim, exclusion))

# æ‰¹é‡æ¨ç†
if len(all_pairs) > 0:
    premises = [p[1] for p in all_pairs]
    hypotheses = [p[0] for p in all_pairs]
    conflict_scores = nli_model.compute_contradiction_scores_batch(premises, hypotheses)
    max_conflict = max(conflict_scores)
```

### 3. å¹¶è¡Œå¤„ç†

```python
from concurrent.futures import ThreadPoolExecutor

def process_paper(paper):
    claims = self.claim_extractor.extract_claims(paper)
    fit_vector = self.stress_tester.test_paper(claims, baseline)
    return fit_vector

# å¹¶è¡Œå¤„ç†å¤šç¯‡è®ºæ–‡
with ThreadPoolExecutor(max_workers=4) as executor:
    fit_vectors = list(executor.map(process_paper, papers))
```

---

## éƒ¨ç½²æ¸…å•

### ä¾èµ–æ›´æ–°

```bash
# requirements.txt æ›´æ–°
sentence-transformers==2.2.2  # for SPECTER2
transformers==4.35.0          # for DeBERTa-MNLI
torch==2.1.0                  # for model inference
hdbscan==0.8.33              # for clustering
```

### é…ç½®æ›´æ–°

```python
# SNSArguments æ–°å¢å‚æ•°
@dataclass
class SNSArguments:
    # ... ç°æœ‰å‚æ•° ...
    
    # æ–°å¢
    embedding_model: str = "specter2"  # or "scincl", "sbert", "fallback"
    nli_model: str = "deberta"         # or "roberta", "fallback"
    enable_compensatory_view: bool = True
    min_facet_diversity: int = 2
    max_dominant_facet_ratio: float = 0.6
```

### ç¯å¢ƒå˜é‡

```bash
# å¯é€‰: è®¾ç½®æ¨¡å‹ç¼“å­˜è·¯å¾„
export TRANSFORMERS_CACHE=/path/to/model/cache
export SENTENCE_TRANSFORMERS_HOME=/path/to/model/cache
```

---

## é£é™©è¯„ä¼°ä¸ç¼“è§£

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|-----|-----|-----|---------|
| Embeddingæ¨¡å‹ä¸‹è½½å¤±è´¥ | ä¸­ | é«˜ | - Fallback to TF-IDF<br>- Pre-download models |
| NLIæ¨ç†å¤ªæ…¢ | ä¸­ | ä¸­ | - Batch processing<br>- Use smaller model (base vs large) |
| è¡¥è§†è§’è´¨é‡ä¸ç¨³å®š | ä½ | ä¸­ | - LLMç”ŸæˆlabelåŠ å¼ºprompt<br>- äººå·¥review option |
| Evolutionåº”ç”¨å¯¼è‡´treeä¸ä¸€è‡´ | ä½ | é«˜ | - å……åˆ†æµ‹è¯•<br>- Tree structure validation<br>- Rollbackæœºåˆ¶ |
| æ€§èƒ½ä¸‹é™ | ä¸­ | ä¸­ | - Embedding/NLIç¼“å­˜<br>- å¹¶è¡Œå¤„ç†<br>- GPUåŠ é€Ÿoption |

---

## æˆåŠŸæ ‡å‡†

### åŠŸèƒ½å®Œæ•´æ€§

- [ ] Phase 2ä½¿ç”¨çœŸå®SPECTER2å’ŒDeBERTa-MNLI
- [ ] Baselineè´¨é‡ä¸è¶³æ—¶è‡ªåŠ¨è§¦å‘è¡¥è§†è§’
- [ ] Evolution proposalåŒ…å«ADD/SPLIT/RENAMEä¸‰ç§æ“ä½œ
- [ ] guidance_pack.jsonåŒ…å«æ¼”åŒ–åçš„taxonomy_v2
- [ ] Must-answer questionsé’ˆå¯¹å…·ä½“evolutionå’Œstress points

### è´¨é‡æŒ‡æ ‡

- [ ] FITåˆ¤å®šå‡†ç¡®ç‡ > 85% (äººå·¥æŠ½æ ·éªŒè¯)
- [ ] Baseline unique facets â‰¥ 2 (100%æ»¡è¶³)
- [ ] Evolution operationsæœ‰è¯æ®æ”¯æŒ (100%æœ‰evidence_spans)
- [ ] guidance_pack.jsoné€šè¿‡schemaéªŒè¯ (100%é€šè¿‡)

### æ€§èƒ½æŒ‡æ ‡

- [ ] End-to-end pipelineè¿è¡Œæ—¶é—´ < 30åˆ†é’Ÿ (100ç¯‡è®ºæ–‡, 15ç¯‡ç»¼è¿°)
- [ ] Embeddingæ¨ç† < 10ms/paper (cached)
- [ ] NLIæ¨ç† < 50ms/å¯¹ (batched)

---

## é™„å½•: å¿«é€Ÿä¿®å¤è„šæœ¬

### è„šæœ¬1: å¿«é€Ÿé›†æˆEmbeddingsåˆ°Phase2

```python
# scripts/quick_fix_phase2_embeddings.py

import sys
sys.path.insert(0, '/home/user/webapp')

from knowledge.sns.modules import phase2_stress_test
from knowledge.sns import embeddings

# Patch EmbeddingBasedRetriever
original_init = phase2_stress_test.EmbeddingBasedRetriever.__init__

def new_init(self, embedding_model_name="specter2"):
    self.model_name = embedding_model_name
    self.embedder = embeddings.create_embedding_model(
        model_type=embedding_model_name,
        device="cpu"
    )

def new_compute_similarity(self, text1, text2):
    emb1 = self.embedder.encode([text1])[0]
    emb2 = self.embedder.encode([text2])[0]
    return self.embedder.similarity(emb1, emb2)

# Apply patches
phase2_stress_test.EmbeddingBasedRetriever.__init__ = new_init
phase2_stress_test.EmbeddingBasedRetriever._compute_similarity = new_compute_similarity

print("âœ… Phase 2 Embeddings patched successfully")
```

### è„šæœ¬2: éªŒè¯æ”¹è¿›æ•ˆæœ

```python
# scripts/validate_improvements.py

def validate_phase2_improvements():
    from knowledge.sns.modules.phase2_stress_test import EmbeddingBasedRetriever
    
    retriever = EmbeddingBasedRetriever("specter2")
    
    # Test 1: ä½¿ç”¨çœŸå®embeddings
    sim = retriever._compute_similarity("deep learning", "neural networks")
    assert 0 <= sim <= 1, "Similarity out of range"
    assert sim > 0.5, "Related terms should have high similarity"
    
    print("âœ… Embeddings working correctly")
    
def validate_evolution_applier():
    from knowledge.sns.modules.taxonomy_evolution_applier import apply_evolution_to_taxonomy
    
    # Create test data
    # ...
    
    # Apply evolution
    view_v2 = apply_evolution_to_taxonomy(view, operations)
    
    # Validate tree structure
    assert len(view_v2.tree.nodes) > len(view.tree.nodes)
    
    print("âœ… Evolution applier working correctly")

if __name__ == "__main__":
    validate_phase2_improvements()
    validate_evolution_applier()
    
    print("\nğŸ‰ All validations passed!")
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**ä½œè€…**: Claude (AI Code Assistant)  
**æœ€åæ›´æ–°**: 2025-12-15  
**çŠ¶æ€**: Ready for implementation
