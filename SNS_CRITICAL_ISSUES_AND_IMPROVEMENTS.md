# SNS ç³»ç»Ÿä¸¥é‡é—®é¢˜åˆ†æä¸æ”¹è¿›å»ºè®®

## åŸºäº Deepfake ä¸»é¢˜è¿è¡Œç»“æœçš„è¯Šæ–­æŠ¥å‘Š

**åˆ†ææ—¥æœŸ**: 2025-12-15  
**æµ‹è¯•ä¸»é¢˜**: deepfake  
**åˆ†æäººå‘˜**: Claude (genspark-ai-developer)

---

## ğŸš¨ å‘ç°çš„ä¸¥é‡é—®é¢˜

### é—®é¢˜ #1: **æ‰€æœ‰è®ºæ–‡100%ä¸é€‚é…** âš ï¸âš ï¸âš ï¸

#### ç°è±¡
```
- Total Papers Analyzed: 5
- FIT: 0 (0.0%)
- FORCE_FIT: 0 (0.0%)
- UNFITTABLE: 10 (100.0%)  â† æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥ï¼
- Average Stress Score: 1.000
- Average Unfittable Score: 1.000
```

#### å…·ä½“æ•°æ®
æ‰€æœ‰5ç¯‡è®ºæ–‡åœ¨2ä¸ªè§†è§’ä¸‹çš„10æ¬¡æµ‹è¯•å…¨éƒ¨æ ‡è®°ä¸º `UNFITTABLE`ï¼ŒFitScore å…¨éƒ¨ä¸ºè´Ÿå€¼ï¼š

| è®ºæ–‡ | View T1 | View T2 |
|------|---------|---------|
| 2306.00863v2 | -0.382 | -0.435 |
| 2305.06564v4 | -0.439 | -0.430 |
| 2505.18587v1 | -0.427 | -0.435 |
| 2511.10212v1 | -0.459 | -0.466 |
| 2412.09921v2 | -0.426 | -0.509 |

#### æ ¹æœ¬åŸå› åˆ†æ

##### 1. **Coverage åˆ†æ•°å¼‚å¸¸ä½**
ä» `fit_vectors.json` åˆ†æï¼š
```json
"scores": {
  "coverage": 0.056,    // â† ä»…5.6%çš„è¦†ç›–ç‡ï¼
  "conflict": 0.071,
  "residual": 0.951,    // â† 95%çš„æ–°é¢–æ€§æ— æ³•åŒ¹é…
  "fit_score": -0.382
}
```

**é—®é¢˜**:
- Coverage åº”è¯¥è‡³å°‘è¾¾åˆ° 0.3-0.5 æ‰åˆç†
- å½“å‰åªæœ‰ ~5-8% çš„è¦†ç›–ç‡
- è¯´æ˜è®ºæ–‡å†…å®¹ä¸åˆ†ç±»èŠ‚ç‚¹å‡ ä¹ä¸åŒ¹é…

**å¯èƒ½åŸå› **:
- âœ… **è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—æœ‰é—®é¢˜**ï¼ˆä½¿ç”¨ "dummy" embeddingï¼‰
- âœ… **è¯æ±‡ç›¸ä¼¼åº¦è®¡ç®—ä¸è¶³**
- âœ… **èŠ‚ç‚¹å®šä¹‰ (NodeDefinition) è´¨é‡å·®**
- âœ… **evidence retrieval å¤±è´¥**

##### 2. **Residual åˆ†æ•°æé«˜**
```json
"residual": 0.951  // â† 95%çš„æ–°é¢–æ€§æ— æ³•åŒ¹é…ä»»ä½•å¶èŠ‚ç‚¹
```

**é—®é¢˜**:
- Residual = 1 - max(cos(novelty_bullet, leaf_embedding))
- é«˜residualæ„å‘³ç€è®ºæ–‡çš„åˆ›æ–°ç‚¹ä¸æ‰€æœ‰å¶èŠ‚ç‚¹éƒ½ä¸ç›¸ä¼¼
- è¯´æ˜åˆ†ç±»ä½“ç³»å¤ªç²—ç³™æˆ–embeddingè´¨é‡å·®

##### 3. **FitScore å…¬å¼è¿‡äºä¸¥æ ¼**
```
FitScore = coverage - 0.8 * conflict - 0.4 * residual
         = 0.056 - 0.8 * 0.071 - 0.4 * 0.951
         = 0.056 - 0.057 - 0.380
         = -0.381
```

**é—®é¢˜**:
- å½“ coverage å¾ˆä½æ—¶ï¼Œresidual çš„æƒ©ç½šï¼ˆ-0.4 * 0.95 = -0.38ï¼‰å ä¸»å¯¼
- å¯¼è‡´å‡ ä¹æ‰€æœ‰è®ºæ–‡éƒ½ä¼šè¢«æ ‡è®°ä¸º UNFITTABLE

---

### é—®é¢˜ #2: **Phase 3 æ²¡æœ‰ç”Ÿæˆä»»ä½•æ¼”åŒ–ææ¡ˆ** âš ï¸âš ï¸

#### ç°è±¡
```json
// stress_clusters.json
[]

// evolution_proposal.json
{
  "operations": [],
  "total_fit_gain": 0.0,
  "total_edit_cost": 0.0,
  "objective_value": 0.0
}
```

#### æ ¹æœ¬åŸå› 

##### 1. **HDBSCAN èšç±»å¤±è´¥**
```python
# 5ç¯‡è®ºæ–‡å¤ªå°‘ï¼Œæ— æ³•å½¢æˆæœ‰æ„ä¹‰çš„èšç±»
min_cluster_size = 3  # é»˜è®¤å€¼
total_stressed_papers = 5  # æ‰€æœ‰è®ºæ–‡éƒ½æ˜¯stressed
```

**é—®é¢˜**:
- HDBSCAN éœ€è¦è¶³å¤Ÿå¤šçš„æ ·æœ¬æ‰èƒ½èšç±»
- 5ç¯‡è®ºæ–‡å¯èƒ½å…¨éƒ¨è¢«æ ‡è®°ä¸ºå™ªå£°ç‚¹ï¼ˆoutliersï¼‰
- å¯¼è‡´ `stress_clusters = []`

##### 2. **æ¼”åŒ–è§„åˆ’å™¨æ²¡æœ‰è§¦å‘**
```python
# Phase3Pipeline.run()
if len(stress_clusters) == 0:
    logger.info("No stress clusters found, skipping evolution planning")
    return [], EvolutionProposal(operations=[], ...)
```

**é—®é¢˜**:
- æ²¡æœ‰èšç±» â†’ æ²¡æœ‰æ¼”åŒ–ææ¡ˆ
- å³ä½¿æ‰€æœ‰è®ºæ–‡éƒ½ä¸é€‚é…ï¼Œç³»ç»Ÿä¹Ÿä¸ä¼šæå‡ºç»“æ„æ›´æ–°

---

### é—®é¢˜ #3: **åŸºçº¿è´¨é‡å·®** âš ï¸

#### ç°è±¡
```
- Total Taxonomy Views: 2
- View T1: APPLICATION_DOMAIN (weight=0.400, 4 leaf nodes)
- View T2: APPLICATION_DOMAIN (weight=0.600, 6 leaf nodes)
```

#### é—®é¢˜

##### 1. **åªæœ‰2ä¸ªè§†è§’ï¼Œä¸”facetç›¸åŒ**
```
T1: APPLICATION_DOMAIN (Audio deepfake detection)
T2: APPLICATION_DOMAIN (Malicious deepfakes)
```

**é—®é¢˜**:
- ä¸¤ä¸ªè§†è§’çš„ facet_label ç›¸åŒï¼ˆéƒ½æ˜¯ APPLICATION_DOMAINï¼‰
- è¿åäº†"è‡³å°‘2ä¸ªä¸åŒfacet"çš„è®¾è®¡è¦æ±‚
- ç¼ºä¹å¤šæ ·æ€§ï¼Œæ— æ³•è¦†ç›–ä¸åŒçš„ç»„ç»‡ç»´åº¦

##### 2. **å¶èŠ‚ç‚¹å¤ªå°‘**
```
T1: 4 leaf nodes
T2: 6 leaf nodes
Total: ~10 leaf nodes (å»é‡åå¯èƒ½æ›´å°‘)
```

**é—®é¢˜**:
- è®¾è®¡è¦æ±‚è‡³å°‘ 20-50 ä¸ªå¶èŠ‚ç‚¹
- å½“å‰åªæœ‰ ~10 ä¸ªèŠ‚ç‚¹
- åˆ†ç±»ä½“ç³»å¤ªç²—ç³™ï¼Œæ— æ³•ç²¾ç»†åŒ¹é…è®ºæ–‡

##### 3. **review papers æ•°é‡ä¸è¶³**
```
top_k_reviews = 5  // åªæ£€ç´¢äº†5ç¯‡reviewè®ºæ–‡
å®é™…æå–è§†è§’: 2ä¸ª  // åªæœ‰2ä¸ªæˆåŠŸæå–
```

**é—®é¢˜**:
- æ£€ç´¢åˆ°çš„reviewå¤ªå°‘
- æå–æˆåŠŸç‡ä½ï¼ˆ5ç¯‡ä¸­åªæœ‰2ç¯‡æˆåŠŸï¼‰
- å¯èƒ½æ˜¯å› ä¸ºLLMæå–å¤±è´¥æˆ–reviewè´¨é‡å·®

---

### é—®é¢˜ #4: **Embedding æ¨¡å‹æ˜¯ "dummy"** âš ï¸âš ï¸âš ï¸

#### ç°è±¡
```python
# SNSArguments
embedding_model="dummy"  # ä½¿ç”¨å ä½ç¬¦ï¼
```

#### å½±å“

è¿™ç›´æ¥å¯¼è‡´ï¼š
1. **Coverage è®¡ç®—å¤±è´¥**
   - `coverage = 0.7 * cov_sem + 0.3 * cov_lex`
   - `cov_sem` ä¾èµ– embedding ç›¸ä¼¼åº¦
   - dummy embedding ä¼šè¿”å›éšæœºæˆ–å›ºå®šå€¼

2. **Residual è®¡ç®—å¤±è´¥**
   - `residual = 1 - max(cos(novelty_bullet, leaf_embedding))`
   - dummy embedding å¯¼è‡´æ‰€æœ‰ç›¸ä¼¼åº¦éƒ½å¾ˆä½

3. **å€™é€‰èŠ‚ç‚¹æ£€ç´¢å¤±è´¥**
   - Phase 2 ä½¿ç”¨ embedding æ£€ç´¢å€™é€‰å¶èŠ‚ç‚¹
   - dummy embedding å¯¼è‡´æ£€ç´¢åˆ°ä¸ç›¸å…³çš„èŠ‚ç‚¹

**è¿™æ˜¯æœ€ä¸¥é‡çš„é—®é¢˜ä¹‹ä¸€ï¼**

---

### é—®é¢˜ #5: **Delta Guidance è´¨é‡å·®** âš ï¸

#### ç°è±¡
```json
// guidance_pack.json
{
  "writing_mode": "ANCHOR_PLUS_DELTA",
  "writing_rules": {
    "do": ["Use main axis structure as the organizational foundation", ...],
    "dont": ["Don't ignore evolution and stress points", ...]
  },
  "outline": [...],  // åªæœ‰åŸºäºmain_axisçš„ç« èŠ‚
  "evolution_summary": [],  // ç©ºçš„ï¼
  "must_answer_questions": [
    "What are the main organizational dimensions in APPLICATION_DOMAIN?",
    "How has the field evolved beyond existing reviews?"
  ]
}
```

#### é—®é¢˜

##### 1. **Writing Mode é€‰æ‹©ä¸å½“**
```
å½“å‰: ANCHOR_PLUS_DELTA (ä½¿ç”¨ä¸»è½´ä½œä¸ºåŸºç¡€)
æœŸæœ›: DELTA_FIRST (å› ä¸ºæ‰€æœ‰è®ºæ–‡éƒ½ä¸é€‚é…ï¼Œåº”è¯¥å¼ºè°ƒæ–°å…´è¶‹åŠ¿)
```

**æ ¹æ®è®¾è®¡æ–‡æ¡£**:
```
DELTA_FIRST æ¡ä»¶:
- EditCost > 3.0  æˆ–
- FitGain > 10.0  æˆ–
- StressReduction > 0.6

å½“å‰æƒ…å†µ:
- 100% è®ºæ–‡ä¸é€‚é…
- Average stress = 1.0
- åº”è¯¥é€‰æ‹© DELTA_FIRST
```

##### 2. **Evolution Summary ä¸ºç©º**
```json
"evolution_summary": []  // æ²¡æœ‰ä»»ä½•æ¼”åŒ–æ“ä½œï¼
```

**é—®é¢˜**:
- ç”±äº Phase 3 æ²¡æœ‰èšç±»ï¼Œæ²¡æœ‰æå‡ºä»»ä½•ç»“æ„æ›´æ–°
- Guidance æ— æ³•å‘Šè¯‰ä¸‹æ¸¸ç³»ç»Ÿ"éœ€è¦æ·»åŠ å“ªäº›æ–°èŠ‚ç‚¹"

##### 3. **Outline ç¼ºä¹çº¦æŸ**
```json
"outline": [
  {
    "section": "DeepFake Generation",
    "subsections": [
      {
        "subsection": "...",
        "required_nodes": [],      // ç©ºçš„ï¼
        "required_citations": [],  // ç©ºçš„ï¼
        "must_answer": [],         // ç©ºçš„ï¼
        "evidence_cards": []       // ç©ºçš„ï¼
      }
    ]
  }
]
```

**é—®é¢˜**:
- ç¼ºå°‘å…·ä½“çš„çº¦æŸå’Œè¯æ®
- ä¸‹æ¸¸ç³»ç»Ÿæ— æ³•çŸ¥é“æ¯ä¸ªå°èŠ‚åº”è¯¥åŒ…å«ä»€ä¹ˆ

---

## ğŸ“‹ ä¼˜å…ˆçº§æ”¹è¿›å»ºè®®

### ğŸ”´ P0: ç«‹å³ä¿®å¤ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰

#### 1. **å¯ç”¨çœŸå®çš„ Embedding æ¨¡å‹**

**å½“å‰é—®é¢˜**: ä½¿ç”¨ `embedding_model="dummy"`

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä¿®æ”¹ run_sns_example.py
igfinder2_args = SNSArguments(
    topic=args.topic,
    output_dir=args.output_dir,
    top_k_reviews=args.top_k_reviews,
    top_k_research_papers=args.top_k_research,
    min_cluster_size=2,
    save_intermediate_results=True,
    embedding_model="allenai/specter2",  # â† æ”¹ä¸ºçœŸå®æ¨¡å‹
    lambda_regularization=0.8,
)
```

**ä¾èµ–å®‰è£…**:
```bash
pip install sentence-transformers
```

**é¢„æœŸæ”¹è¿›**:
- Coverage åˆ†æ•°æå‡è‡³ 0.3-0.5
- Residual åˆ†æ•°é™ä½è‡³ 0.4-0.6
- FitScore æå‡ï¼Œéƒ¨åˆ†è®ºæ–‡å¯èƒ½å˜ä¸º FIT æˆ– FORCE_FIT

---

#### 2. **è°ƒæ•´ FitScore é˜ˆå€¼å’Œå…¬å¼**

**å½“å‰é—®é¢˜**: é˜ˆå€¼å¤ªä¸¥æ ¼ï¼Œå¯¼è‡´æ‰€æœ‰è®ºæ–‡éƒ½ UNFITTABLE

**ä¿®å¤æ–¹æ¡ˆ A**: æ”¾å®½é˜ˆå€¼
```python
# å½“å‰é˜ˆå€¼ï¼ˆdataclass_v2.py æˆ– phase2_stress_test.pyï¼‰
UNFITTABLE: coverage < 0.45 or conflict > 0.55

# å»ºè®®è°ƒæ•´
UNFITTABLE: coverage < 0.25 or conflict > 0.7  # æ›´å®½æ¾
FORCE_FIT: 0.25 <= coverage < 0.40 or residual > 0.5
FIT: coverage >= 0.40 and conflict < 0.7 and residual < 0.5
```

**ä¿®å¤æ–¹æ¡ˆ B**: è°ƒæ•´å…¬å¼æƒé‡
```python
# å½“å‰å…¬å¼
fit_score = coverage - 0.8 * conflict - 0.4 * residual

# å»ºè®®è°ƒæ•´ï¼ˆé™ä½ residual æƒé‡ï¼‰
fit_score = coverage - 0.6 * conflict - 0.2 * residual
```

**ç†ç”±**:
- å½“ embedding è´¨é‡å·®æ—¶ï¼Œresidual ä¼šå¼‚å¸¸é«˜
- é™ä½ residual æƒé‡å¯ä»¥è®© coverage å’Œ conflict å‘æŒ¥æ›´å¤§ä½œç”¨

---

#### 3. **å¢åŠ  Review å’Œ Research Paper æ•°é‡**

**å½“å‰é—®é¢˜**: æ ·æœ¬å¤ªå°‘

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# run_sns_example.py
parser.add_argument(
    '--top-k-reviews',
    type=int,
    default=15,  # â† ä»5å¢åŠ åˆ°15
    help='Number of review papers to retrieve'
)
parser.add_argument(
    '--top-k-research',
    type=int,
    default=30,  # â† ä»10å¢åŠ åˆ°30
    help='Number of research papers to retrieve'
)
```

**é¢„æœŸæ”¹è¿›**:
- æ›´å¤šè§†è§’ï¼ˆ3-5ä¸ªï¼‰
- æ›´å¤šå¶èŠ‚ç‚¹ï¼ˆ20-50ä¸ªï¼‰
- è¶³å¤Ÿçš„è®ºæ–‡è¿›è¡Œèšç±»ï¼ˆ30ç¯‡ï¼‰

---

#### 4. **é™ä½ HDBSCAN min_cluster_size**

**å½“å‰é—®é¢˜**: min_cluster_size=3 å¯¹å°æ•°æ®é›†å¤ªå¤§

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# SNSArguments
SNSArguments(
    ...,
    min_cluster_size=2,  # â† ä»3é™ä½åˆ°2
)
```

æˆ–è€…åŠ¨æ€è°ƒæ•´ï¼š
```python
# Phase3Pipeline.__init__
def __init__(self, lm, min_cluster_size=3, lambda_reg=0.8):
    self.clusterer = StressClusterer(
        min_cluster_size=max(2, min(min_cluster_size, len(papers) // 5))
        # åŠ¨æ€è°ƒæ•´ï¼šè‡³å°‘2ï¼Œæœ€å¤šä¸è¶…è¿‡è®ºæ–‡æ•°çš„1/5
    )
```

**é¢„æœŸæ”¹è¿›**:
- èƒ½å¤Ÿå½¢æˆè‡³å°‘1-2ä¸ªèšç±»
- Phase 3 å¯ä»¥æå‡ºæ¼”åŒ–æ“ä½œ

---

### ğŸŸ¡ P1: é‡è¦ä¼˜åŒ–ï¼ˆæå‡è´¨é‡ï¼‰

#### 5. **æ”¹è¿› NodeDefinition è´¨é‡**

**é—®é¢˜**: Coverage ä½å¯èƒ½æ˜¯å› ä¸ºèŠ‚ç‚¹å®šä¹‰è´¨é‡å·®

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# schemas_v2.py - NodeDefinitionSignature
class NodeDefinitionSignature(dspy.Signature):
    """..."""
    
    # å¢å¼º prompt
    definition = dspy.OutputField(
        desc="""Detailed definition of this node (50-100 words).
        
        REQUIREMENTS:
        - Use concrete technical terms and keywords
        - Include synonyms and related concepts
        - Mention representative papers or methods
        - Be specific, not generic
        
        GOOD example: "Convolutional Neural Networks (CNNs) for image deepfake 
        detection, including ResNet, VGG, and their variants. These methods use 
        2D convolutions to extract spatial features from image frames."
        
        BAD example: "Methods that use neural networks for detection."
        """
    )
```

**é¢„æœŸæ”¹è¿›**:
- æ›´ä¸°å¯Œçš„å…³é”®è¯
- æ›´é«˜çš„è¯æ±‡ç›¸ä¼¼åº¦ï¼ˆcov_lexï¼‰
- Coverage æå‡ 0.1-0.2

---

#### 6. **æ·»åŠ å›é€€æœºåˆ¶ï¼šå¼ºåˆ¶èšç±»**

**é—®é¢˜**: HDBSCAN å¯èƒ½è¿”å›ç©ºèšç±»

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# phase3_evolution.py - StressClusterer
def cluster_stressed_papers(self, fit_vectors, papers, baseline):
    # å°è¯• HDBSCAN
    clusters = self._hdbscan_cluster(...)
    
    # å›é€€ï¼šå¦‚æœæ²¡æœ‰èšç±»ï¼Œä½¿ç”¨ç®€å•çš„é˜ˆå€¼èšç±»
    if len(clusters) == 0:
        logger.warning("HDBSCAN found no clusters, using fallback clustering")
        clusters = self._fallback_cluster(fit_vectors, papers, baseline)
    
    return clusters

def _fallback_cluster(self, fit_vectors, papers, baseline):
    """
    å›é€€ç­–ç•¥ï¼šåŸºäº failure_signature ç›¸ä¼¼åº¦èšç±»
    """
    # æŒ‰ failure_signature åˆ†ç»„
    # è‡³å°‘ä¿è¯æ¯ä¸ªé«˜åº¦stressedçš„è®ºæ–‡éƒ½åœ¨æŸä¸ª"cluster"ä¸­
    ...
```

---

#### 7. **å®ç° Writing Mode è‡ªåŠ¨åˆ¤å®š**

**é—®é¢˜**: å½“å‰æ€»æ˜¯é€‰æ‹© ANCHOR_PLUS_DELTA

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# phase4_guidance.py - AxisSelector
def select_main_axis_with_mode(self, baseline, reconstruction_scores):
    # 1. é€‰æ‹©ä¸»è½´ï¼ˆåŸºäº reconstruction_scoreï¼‰
    best_view = max(reconstruction_scores, key=lambda s: s.combined_score)
    
    # 2. åˆ¤å®šå†™ä½œæ¨¡å¼
    if best_view.edit_cost > 3.0 or best_view.fit_gain > 10.0:
        mode = WritingMode.DELTA_FIRST
    elif best_view.stress_reduction > 0.6:
        mode = WritingMode.DELTA_FIRST
    else:
        mode = WritingMode.ANCHOR_PLUS_DELTA
    
    logger.info(f"Selected writing mode: {mode.value}")
    logger.info(f"  Reason: EditCost={best_view.edit_cost:.1f}, "
                f"FitGain={best_view.fit_gain:.1f}, "
                f"StressReduction={best_view.stress_reduction:.2f}")
    
    return best_view, mode
```

**å½“å‰é—®é¢˜**:
- reconstruction_scores å¯èƒ½ä¸ºç©ºï¼ˆå› ä¸º Phase 3 æ²¡æœ‰è®¡ç®—ï¼‰
- éœ€è¦æ·»åŠ é»˜è®¤é€»è¾‘

---

#### 8. **ç”Ÿæˆå…·ä½“çš„ Outline çº¦æŸ**

**é—®é¢˜**: evidence_cards, required_citations éƒ½æ˜¯ç©ºçš„

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# phase4_guidance.py - GuidanceGenerator
def _generate_outline(self, main_axis, aux_axis, papers, fit_vectors):
    outline = []
    
    for child_node in main_axis.tree.get_children("ROOT"):
        section = Section(
            section=child_node.name,
            subsections=[]
        )
        
        # æ‰¾åˆ°åŒ¹é…è¿™ä¸ªèŠ‚ç‚¹çš„è®ºæ–‡
        relevant_papers = self._find_papers_for_node(
            child_node, papers, fit_vectors, main_axis
        )
        
        for paper in relevant_papers[:3]:  # æ¯ä¸ªèŠ‚ç‚¹æœ€å¤š3ç¯‡
            # æå– evidence card
            evidence_cards = self._extract_evidence_cards(
                paper, child_node, fit_vectors
            )
            
            subsection = Subsection(
                subsection=f"{child_node.name} - {paper.title[:50]}",
                required_nodes=[child_node.path],
                required_citations=[paper.paper_id],
                must_answer=[
                    f"How does {paper.title[:30]}... contribute to {child_node.name}?"
                ],
                evidence_cards=evidence_cards
            )
            section.subsections.append(subsection)
        
        outline.append(section)
    
    return outline
```

---

### ğŸŸ¢ P2: å¢å¼ºåŠŸèƒ½ï¼ˆé•¿æœŸä¼˜åŒ–ï¼‰

#### 9. **æ·»åŠ è´¨é‡æ£€æŸ¥å’Œè­¦å‘Š**

```python
# engine_v2.py - SNSRunner
def _validate_results(self):
    """éªŒè¯ç»“æœè´¨é‡å¹¶è¾“å‡ºè­¦å‘Š"""
    
    # æ£€æŸ¥1: Fit rate
    fit_rate = sum(1 for fv in self.fit_vectors 
                   for fr in fv.fit_reports 
                   if fr.label == FitLabel.FIT) / len(self.fit_vectors)
    
    if fit_rate < 0.1:
        logger.warning(f"âš ï¸ Very low fit rate: {fit_rate:.1%}")
        logger.warning("  Possible causes:")
        logger.warning("  - Embedding model quality (check embedding_model parameter)")
        logger.warning("  - NodeDefinition quality (review extraction might have failed)")
        logger.warning("  - Baseline diversity (may need more review papers)")
    
    # æ£€æŸ¥2: Cluster count
    if len(self.stress_clusters) == 0:
        logger.warning("âš ï¸ No stress clusters formed")
        logger.warning("  Possible causes:")
        logger.warning("  - Too few stressed papers (need at least 5-10)")
        logger.warning("  - min_cluster_size too large")
        logger.warning("  - Papers too dissimilar (no clear failure patterns)")
    
    # æ£€æŸ¥3: Baseline quality
    unique_facets = len(set(v.facet_label for v in self.baseline.views))
    if unique_facets < 2:
        logger.warning(f"âš ï¸ Only {unique_facets} unique facets in baseline")
        logger.warning("  Recommendation: Increase top_k_reviews parameter")
```

---

#### 10. **æ·»åŠ ä¸­é—´ç»“æœå¯è§†åŒ–**

```python
# æ–°å¢å·¥å…·å‡½æ•°
def visualize_fit_distribution(fit_vectors):
    """ç”Ÿæˆ fit score åˆ†å¸ƒå›¾"""
    import matplotlib.pyplot as plt
    
    scores = [fr.scores.fit_score 
              for fv in fit_vectors 
              for fr in fv.fit_reports]
    
    plt.hist(scores, bins=20, edgecolor='black')
    plt.axvline(x=0, color='r', linestyle='--', label='Threshold')
    plt.xlabel('Fit Score')
    plt.ylabel('Count')
    plt.title('Fit Score Distribution')
    plt.legend()
    plt.savefig('fit_score_distribution.png')
    logger.info("Saved fit score distribution to fit_score_distribution.png")
```

---

#### 11. **æ”¯æŒå¢é‡æ›´æ–°**

```python
# æ”¯æŒåœ¨å·²æœ‰baselineåŸºç¡€ä¸Šå¢é‡æ·»åŠ è®ºæ–‡
def incremental_run(self, new_papers: List[ResearchPaper]):
    """å¢é‡è¿è¡Œï¼šåªæµ‹è¯•æ–°è®ºæ–‡ï¼Œä¸é‡æ–°æ„å»ºbaseline"""
    
    # Phase 2: åªæµ‹è¯•æ–°è®ºæ–‡
    new_fit_vectors = self.phase2.run(new_papers, self.baseline)
    
    # åˆå¹¶åˆ°ç°æœ‰ç»“æœ
    self.fit_vectors.extend(new_fit_vectors)
    
    # Phase 3: é‡æ–°èšç±»ï¼ˆä½¿ç”¨æ‰€æœ‰è®ºæ–‡ï¼‰
    self.stress_clusters, self.evolution_proposal = self.phase3.run(
        self.fit_vectors, self.research_papers + new_papers, self.baseline
    )
    
    # Phase 4: æ›´æ–°guidance
    ...
```

---

## ğŸ¯ æ¨èçš„ä¿®å¤é¡ºåº

### ç¬¬ä¸€æ­¥ï¼šç«‹å³ä¿®å¤ï¼ˆä»Šå¤©ï¼‰
1. âœ… å¯ç”¨ SPECTER2 embedding
2. âœ… æ”¾å®½ FitScore é˜ˆå€¼
3. âœ… å¢åŠ è®ºæ–‡æ•°é‡ï¼ˆtop_k_reviews=15, top_k_research=30ï¼‰
4. âœ… é™ä½ min_cluster_size=2

### ç¬¬äºŒæ­¥ï¼šè´¨é‡æå‡ï¼ˆæœ¬å‘¨ï¼‰
5. âœ… æ”¹è¿› NodeDefinition prompt
6. âœ… æ·»åŠ èšç±»å›é€€æœºåˆ¶
7. âœ… å®ç° Writing Mode è‡ªåŠ¨åˆ¤å®š
8. âœ… æ·»åŠ è´¨é‡æ£€æŸ¥è­¦å‘Š

### ç¬¬ä¸‰æ­¥ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸‹å‘¨ï¼‰
9. âœ… ç”Ÿæˆå…·ä½“çš„ Outline çº¦æŸ
10. âœ… æ·»åŠ å¯è§†åŒ–å·¥å…·
11. âœ… æ”¯æŒå¢é‡æ›´æ–°

---

## ğŸ“Š é¢„æœŸæ”¹å–„æ•ˆæœ

### ä¿®å¤å‰ï¼ˆå½“å‰çŠ¶æ€ï¼‰
```
âœ— FIT: 0%
âœ— FORCE_FIT: 0%
âœ— UNFITTABLE: 100%
âœ— Stress Clusters: 0
âœ— Evolution Operations: 0
âœ— Guidance Quality: Low
```

### ä¿®å¤åï¼ˆé¢„æœŸï¼‰
```
âœ“ FIT: 20-40%
âœ“ FORCE_FIT: 30-40%
âœ“ UNFITTABLE: 20-50%
âœ“ Stress Clusters: 1-3
âœ“ Evolution Operations: 2-5
âœ“ Guidance Quality: Medium-High
```

---

## ğŸ”§ å¿«é€Ÿä¿®å¤è„šæœ¬

åˆ›å»ºä¸€ä¸ªå¿«é€Ÿä¿®å¤é…ç½®æ–‡ä»¶ï¼š

```python
# quick_fix_config.py
from knowledge_storm.sns import SNSArguments

def get_improved_args(topic, output_dir):
    """è¿”å›æ”¹è¿›åçš„é…ç½®"""
    return SNSArguments(
        topic=topic,
        output_dir=output_dir,
        
        # å¢åŠ æ ·æœ¬æ•°é‡
        top_k_reviews=15,           # ä»5å¢åŠ åˆ°15
        top_k_research_papers=30,   # ä»10å¢åŠ åˆ°30
        
        # é™ä½èšç±»é˜ˆå€¼
        min_cluster_size=2,         # ä»3é™ä½åˆ°2
        
        # å¯ç”¨çœŸå®embedding
        embedding_model="allenai/specter2",  # ä¸å†ä½¿ç”¨dummy
        
        # å…¶ä»–å‚æ•°
        save_intermediate_results=True,
        lambda_regularization=0.8,
    )
```

ä½¿ç”¨æ–¹å¼ï¼š
```python
# åœ¨ run_sns_example.py ä¸­
from quick_fix_config import get_improved_args

args = get_improved_args(args.topic, args.output_dir)
runner = SNSRunner(args=args, lm_configs=lm_configs, rm=rm)
```

---

## ğŸ“ æ€»ç»“

### å½“å‰æœ€ä¸¥é‡çš„é—®é¢˜
1. ğŸ”´ **Embedding æ¨¡å‹æ˜¯ dummy**ï¼ˆå¯¼è‡´æ‰€æœ‰åˆ†æ•°ä¸å‡†ç¡®ï¼‰
2. ğŸ”´ **FitScore é˜ˆå€¼å¤ªä¸¥æ ¼**ï¼ˆå¯¼è‡´100%ä¸é€‚é…ï¼‰
3. ğŸ”´ **æ ·æœ¬æ•°é‡å¤ªå°‘**ï¼ˆå¯¼è‡´æ— æ³•èšç±»å’Œæ¼”åŒ–ï¼‰

### æœ€ç´§æ€¥çš„ä¿®å¤
1. å¯ç”¨ SPECTER2
2. è°ƒæ•´é˜ˆå€¼
3. å¢åŠ è®ºæ–‡æ•°é‡

### é¢„æœŸæ”¹å–„
- FIT rate: 0% â†’ 20-40%
- èšç±»æ•°é‡: 0 â†’ 1-3
- æ¼”åŒ–æ“ä½œ: 0 â†’ 2-5
- æ•´ä½“å¯ç”¨æ€§: âŒ â†’ âœ…

---

**æŠ¥å‘Šå®Œæˆæ—¶é—´**: 2025-12-15  
**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: å®æ–½ P0 ä¿®å¤ï¼Œé‡æ–°æµ‹è¯•ç³»ç»Ÿ
